{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pyaudio\n",
    "import wave\n",
    "import datetime\n",
    "import wave\n",
    "import replicate\n",
    "import os\n",
    "from IPython.display import display, Image\n",
    "openai.api_key = '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'\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = \"f8e48dc1cf76fed994b710f96f75788eea8f082a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio(chunk_size=1024, sample_rate=44100, duration=5):\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=pyaudio.paInt16,\n",
    "                    channels=1,\n",
    "                    rate=sample_rate,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=chunk_size)\n",
    "\n",
    "    # record audio for 5 seconds\n",
    "    print(\"Recording audio...\")\n",
    "    frames = []\n",
    "    for i in range(0, int(sample_rate / chunk_size * duration)):\n",
    "        data = stream.read(chunk_size)\n",
    "        frames.append(data)\n",
    "\n",
    "    # stop recording and save audio to file\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    filename = f\"audio/audio_{now}.wav\"\n",
    "\n",
    "    wf = wave.open(filename, 'wb')\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "    wf.setframerate(sample_rate)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "    print(f\"Audio saved to {filename}\")\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe using OpenAI's Whisper API\n",
    "def transcribe(filename):\n",
    "    audio_file= open(filename, \"rb\")\n",
    "    transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to image prompt\n",
    "def text_to_chatgpt_request(text):\n",
    "    chatgpt_request = f\"\"\"\n",
    "    We are playing dungeons and dragons and below is a transcript. \n",
    "    Can you create a prompt for a text-to-image model from the following. \n",
    "\n",
    "    \"{text}\"\n",
    "\n",
    "    Please only reply with the prompt and nothing else.\"\"\"\n",
    "    return chatgpt_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_to_image(prompt = 'generic dungeons and dragons scenes'):\n",
    "    res = replicate.run(\n",
    "            \"stability-ai/stable-diffusion:27b93a2413e7f36cd83da926f3656280b2931564ff050bf9575f1fdf9bcd7478\",\n",
    "            input={\"prompt\": prompt}\n",
    "        )\n",
    "    return res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_image(url):\n",
    "    display(Image(url=url))\n",
    "    return Image(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(duration = 5):\n",
    "    filename = record_audio(duration=duration)\n",
    "    transcript = transcribe(filename)\n",
    "    print(transcript['text'])\n",
    "    chatgpt_request = text_to_chatgpt_request(transcript['text'])\n",
    "    print(chatgpt_request)\n",
    "    res = prompt_to_image(transcript['text'])\n",
    "    url_to_image(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved to audio/audio_2023-04-16_16-07-57.wav\n",
      "You enter a black forest and there's a white dragon breathing red fire.\n",
      "Can you create a prompt for a text-to-image model from the following:\n",
      "\n",
      "    \"You enter a black forest and there's a white dragon breathing red fire.\"\n",
      "\n",
      "    Please only reply with the prompt and nothing else.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://replicate.delivery/pbxt/zsAWiRpTeKSkNyr0BrHleOigjLgpFm5AS9eNi1741MtnWokhA/out-0.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b6ae6f2cb7de6a41e3fc1c901fff18bdf4f8e058d396cbde356e323499d071f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
