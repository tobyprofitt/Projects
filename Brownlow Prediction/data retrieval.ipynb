{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix list:\n",
    "- The Year scraping bit isn't working past 2003. It's getting crowd attendance.\n",
    "- Need to add player's team and a 'win' column."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For future reference:\n",
    "2001 to 2006 has format:\n",
    "columns=[\"Player\", \"K\", \"HB\", \"D\", \"M\", \"G\", \"B\", \"T\", \"HO\", \"FF\", \"FA\"]\n",
    "\n",
    "2007 to 2009 has format:\n",
    "columns=[\"Player\", \"K\", \"HB\", \"D\", \"M\", \"G\", \"B\", \"T\", \"HO\", \"GA\", \"I50\", \"FF\", \"FA\", \"AF\", \"SC\"]\n",
    "\n",
    "2010 to 2022 has format:\n",
    "columns=[\"Player\", \"K\", \"HB\", \"D\", \"M\", \"G\", \"B\", \"T\", \"HO\", \"GA\", \"I50\", \"CL\", \"CG\", \"R50\", \"FF\", \"FA\", \"AF\", \"SC\"]\n",
    "\n",
    "Note that 2010 onwards also has advanced stats available: add afl/footy/ft_match_statistics?mid=5089&advv=Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Processed match ID 1\n",
      "2\n",
      "Processed match ID 2\n",
      "3\n",
      "Processed match ID 3\n",
      "4\n",
      "Processed match ID 4\n",
      "5\n",
      "Processed match ID 5\n",
      "6\n",
      "Processed match ID 6\n",
      "7\n",
      "Processed match ID 7\n",
      "8\n",
      "Processed match ID 8\n",
      "9\n",
      "Processed match ID 9\n",
      "10\n",
      "Processed match ID 10\n",
      "11\n",
      "Processed match ID 11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "first_game = 1\n",
    "last_game = 10741\n",
    "\n",
    "dfs = []\n",
    "bad_match_ids = []\n",
    "for match_id in (range(first_game, last_game+1)):\n",
    "    try:\n",
    "        print(match_id)\n",
    "        url = f\"https://www.footywire.com/afl/footy/ft_match_statistics?mid={match_id}\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Find the table element with the match statistics\n",
    "        match_stats_table = soup.find(\"table\", {\"id\": \"match-statistics-div\"})\n",
    "        if match_stats_table is None:\n",
    "            print(f\"No match statistics div found for match ID {match_id}\")\n",
    "            continue\n",
    "\n",
    "        # Find the round number and year\n",
    "        if match_id < 1840:\n",
    "            year_round = soup.find('td', {\"class\": \"lnorm\", \"height\":\"22\"})\n",
    "            round = year_round.text[0:year_round.text.find(',')]\n",
    "            year = year_round.text[-4:]\n",
    "        else:\n",
    "            year_round = soup.find('td', {\"class\": \"lnorm\", \"height\":\"22\"})\n",
    "            round = year_round.text[0:year_round.text.find(',')]\n",
    "            year_round = soup.find('td', {\"class\": \"lnorm\", \"height\":\"22\"}).find_next('td', {\"class\": \"lnorm\", \"height\":\"22\"})\n",
    "            year = year_round.text[-4:]\n",
    "\n",
    "        if 'final' in round.lower():\n",
    "            print(f\"There is 'final' in this round: {round}\")\n",
    "            continue\n",
    "\n",
    "        # Find the rows with player statistics\n",
    "        player_stats_rows = match_stats_table.find_all(\"tr\", {\"class\": [\"darkcolor\", \"lightcolor\"], \"onmouseover\": \"this.className='highlightcolor';\", \"onmouseout\": [\"this.className='darkcolor';\", \"this.className='lightcolor';\"]})\n",
    "        first_team = soup.find(\"td\", {\"class\": \"innertbtitle\", \"align\": \"left\"}).find(\"b\").text\n",
    "        first_team = first_team[:first_team.find(\"Match Statistics\")].strip()\n",
    "        second_team = soup.find(\"td\", {\"class\": \"innertbtitle\", \"align\": \"left\"}).find_next(\"td\", {\"class\": \"innertbtitle\", \"align\": \"left\"}).find(\"b\").text\n",
    "        second_team = second_team[:second_team.find(\"Match Statistics\")].strip()\n",
    "\n",
    "        if 'defeats' in soup.title.text.lower():\n",
    "            winner = first_team\n",
    "        else:\n",
    "            winner = second_team\n",
    "\n",
    "        # Extract the data from each row and create a pandas dataframe\n",
    "        data = []\n",
    "        for i, row in enumerate(player_stats_rows):\n",
    "            team = first_team if i < len(player_stats_rows)/2 else second_team\n",
    "            cols = row.find_all(\"td\")\n",
    "            cols = [col.text.strip() for col in cols]\n",
    "            if len(cols) == 11:\n",
    "                result = 1 if team == winner else 0\n",
    "                new_row = [year, round, team, result] + cols\n",
    "                data.append(new_row)\n",
    "                columns=[\"Year\", \"Round\", \"Team Name\", \"Win\", \"Player\", \"K\", \"HB\", \"D\", \"M\", \"G\", \"B\", \"T\", \"HO\", \"FF\", \"FA\"]\n",
    "            elif len(cols) == 15:\n",
    "                result = 1 if team == winner else 0\n",
    "                new_row = [year, round, team, result] + cols\n",
    "                data.append(new_row)\n",
    "                columns=[\"Year\", \"Round\", \"Team Name\", \"Win\", \"Player\", \"K\", \"HB\", \"D\", \"M\", \"G\", \"B\", \"T\", \"HO\", \"GA\", \"I50\", \"FF\", \"FA\", \"AF\", \"SC\"]\n",
    "            elif len(cols) == 18:\n",
    "                result = 1 if team == winner else 0\n",
    "                new_row = [year, round, team, result] + cols\n",
    "                data.append(new_row)\n",
    "                columns=[\"Year\", \"Round\", \"Team Name\", \"Win\", \"Player\", \"K\", \"HB\", \"D\", \"M\", \"G\", \"B\", \"T\", \"HO\", \"GA\", \"I50\", \"CL\", \"CG\", \"R50\", \"FF\", \"FA\", \"AF\", \"SC\"]\n",
    "\n",
    "        if data:\n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            df[\"Match ID\"] = match_id   \n",
    "\n",
    "            # Get Brownlow votes\n",
    "            brownlow_votes = soup.find(string=re.compile(\"Brownlow Votes:\"))\n",
    "            if brownlow_votes:\n",
    "                votes = {}\n",
    "                for i in range(3):\n",
    "                    player = brownlow_votes.find_next(\"a\").text.strip()\n",
    "                    player_parts = player.split(\" \")\n",
    "                    last_name = player_parts[-1]\n",
    "                    first_initial = player_parts[0][0]\n",
    "                    player_reversed = \" \".join(player_parts[::-1])\n",
    "                    votes[player_reversed] = 3-i\n",
    "                    brownlow_votes = brownlow_votes.find_next(\"a\")\n",
    "                df[\"Votes\"] = df[\"Player\"].apply(lambda x: votes.get(x.split()[-1] + ' ' + x.split()[0][0], 0))\n",
    "            else:\n",
    "                df[\"Votes\"] = 0\n",
    "\n",
    "            dfs.append(df)\n",
    "            print(f\"Processed match ID {match_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing match ID {match_id}: {e}\")\n",
    "        bad_match_ids.append(match_id)\n",
    "\n",
    "# Concatenate all dataframes into a single one\n",
    "df_final = pd.concat(dfs)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "df_final.to_csv(\"player_stats.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td class=\"lnorm\" height=\"22\">\n",
       "Saturday, 26th August 2006</td>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the year in the header of the page\n",
    "soup.find('td', {\"class\": \"lnorm\", \"height\":\"22\"})\n",
    "\n",
    "# it's actually the next element\n",
    "soup.find('td', {\"class\": \"lnorm\", \"height\":\"22\"}).find_next('td', {\"class\": \"lnorm\", \"height\":\"22\"})\n",
    "\n",
    "# find the year when the result is like this: <td class=\"lnorm\" height=\"22\"> Saturday, 26th August 2006</td>\n",
    "soup.find('td', {\"class\": \"lnorm\", \"height\":\"22\"}).text[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSaturday'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7a8cc386e849d53507c66328c08418986bc7aeaf3690913744813adc9439505"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
